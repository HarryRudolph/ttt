{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00f36c5-1a91-4a35-807d-bfbfeecde17c",
   "metadata": {},
   "source": [
    "# Learning MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cdbe48a-5dbd-4237-8012-bdb4864485fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip, tarfile\n",
    "import numpy as np\n",
    "\n",
    "from tinygrad import Tensor, nn\n",
    "from tinygrad.nn.state import get_parameters\n",
    "from tinygrad.helpers import fetch\n",
    "\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "832582fb-2cd4-4330-ae42-fc5f0098669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = lambda file: np.frombuffer(gzip.open(file).read(), dtype=np.uint8).copy()\n",
    "BASE_URL = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"   # http://yann.lecun.com/exdb/mnist/ lacks https\n",
    "X_train = parse(fetch(f\"{BASE_URL}train-images-idx3-ubyte.gz\"))[0x10:].reshape((-1, 28*28)).astype(np.float32)\n",
    "Y_train = parse(fetch(f\"{BASE_URL}train-labels-idx1-ubyte.gz\"))[8:].astype(np.int8)\n",
    "X_test = parse(fetch(f\"{BASE_URL}t10k-images-idx3-ubyte.gz\"))[0x10:].reshape((-1, 28*28)).astype(np.float32)\n",
    "Y_test = parse(fetch(f\"{BASE_URL}t10k-labels-idx1-ubyte.gz\"))[8:].astype(np.int8)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42607ebb-5f0a-4297-9f98-89ed779ab62b",
   "metadata": {},
   "source": [
    "## Tinygrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a71d431e-ab5f-4411-b837-a5f5b8c0df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet:\n",
    "    def __init__(self):\n",
    "      self.l1 = Tensor.scaled_uniform(784, 128)\n",
    "      self.l2 = Tensor.scaled_uniform(128, 10)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "      x = x.dot(self.l1).relu()\n",
    "      x = x.dot(self.l2)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fade207-c8b9-4e27-8d5e-ebf1e2a74ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0190bd8d-1908-4449-8ae7-0f526efe9b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Tensor <LB METAL (784, 128) float (<BinaryOps.MUL: 3>, None)> on METAL with grad None>,\n",
       " <Tensor <LB METAL (128, 10) float (<BinaryOps.MUL: 3>, None)> on METAL with grad None>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953ecaf5-943a-4e79-af4c-d8ca5546b7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tinygrad.nn.optim.LARS at 0x10cfa1eb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = nn.optim.SGD(get_parameters(model))\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "827ef40f-c602-4aa4-806f-fd33d712a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, Y_train, optim, steps, BS=128, lossfn=lambda out, y: out.sparse_categorical_crossentropy(y),\n",
    "          transform=lambda x: x, target_transform=lambda x: x, noloss=False, allow_jit=True):\n",
    "\n",
    "  def train_step(x, y):\n",
    "    out = model.forward(x)\n",
    "    loss = lossfn(out, y)\n",
    "    optim.zero_grad() \n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    cat = out.argmax(axis=-1)\n",
    "    accuracy = (cat==y).mean()\n",
    "    return loss.realize(), accuracy.realize()\n",
    "\n",
    "  with Tensor.train():\n",
    "    losses, accuracies = [], []\n",
    "    for i in (t := trange(steps)):\n",
    "      samp = np.random.randint(0, X_train.shape[0], size=(BS))\n",
    "      x = Tensor(X_train[samp], requires_grad=False)\n",
    "      y = Tensor(Y_train[samp])\n",
    "\n",
    "      loss, accuracy = train_step(x, y)\n",
    "      loss, accuracy = loss.numpy(), accuracy.numpy()\n",
    "      losses.append(loss)\n",
    "      accuracies.append(accuracy)\n",
    "      t.set_description(\"loss %.2f accuracy %.2f\" % (loss, accuracy))\n",
    "  return [losses, accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "918fb1be-0d2d-48ca-82e4-ea8d13b1a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, Y_test):\n",
    "  BS = 128\n",
    "  Tensor.training = False \n",
    "\n",
    "  def numpy_eval(Y_test, num_classes):\n",
    "    Y_test_preds_out = np.zeros(list(Y_test.shape) + [num_classes])\n",
    "    for i in trange((len(Y_test)-1)//BS+1):\n",
    "      x = Tensor(X_test[i*BS:(i+1)*BS])\n",
    "      out = model.forward(x)\n",
    "      Y_test_preds_out[i*BS:(i+1)*BS] = out.numpy()\n",
    "    Y_test_preds = np.argmax(Y_test_preds_out, axis=-1)\n",
    "    return (Y_test == Y_test_preds).mean(), Y_test_preds\n",
    "\n",
    "  num_classes = Y_test.max().astype(int)+1\n",
    "  acc, Y_test_pred = numpy_eval(Y_test, num_classes)\n",
    "  print(f\"test set accuracy is {acc}\")\n",
    "  return acc\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be83cfd7-da96-4b18-a379-fe8234208a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.05 accuracy 1.00: 100%|██████████████| 1000/1000 [00:17<00:00, 57.92it/s]\n",
      "100%|██████████████████████████████████████████| 79/79 [00:00<00:00, 339.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.9772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9772"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, X_train, Y_train, optimizer, 1000, BS=256)\n",
    "evaluate(model, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf88c0d-1dc8-479e-85fc-c67e0427c927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinygrad",
   "language": "python",
   "name": "tinygrad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

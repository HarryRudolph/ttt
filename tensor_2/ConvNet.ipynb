{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e2af979-f1bd-4144-b64c-2211f5c8f4d8",
   "metadata": {},
   "source": [
    "# ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a8bea8-2afd-4d24-9098-31ebe9ee85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip, tarfile\n",
    "import numpy as np\n",
    "\n",
    "from tinygrad import Tensor, nn\n",
    "from tinygrad.nn.state import get_parameters\n",
    "from tinygrad.helpers import fetch\n",
    "\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a00fe7-e8f2-4ee2-a5a9-a5672213c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = lambda file: np.frombuffer(gzip.open(file).read(), dtype=np.uint8).copy()\n",
    "BASE_URL = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"   # http://yann.lecun.com/exdb/mnist/ lacks https\n",
    "X_train = parse(fetch(f\"{BASE_URL}train-images-idx3-ubyte.gz\"))[0x10:].reshape((-1, 28*28)).astype(np.float32)\n",
    "Y_train = parse(fetch(f\"{BASE_URL}train-labels-idx1-ubyte.gz\"))[8:].astype(np.int8)\n",
    "X_test = parse(fetch(f\"{BASE_URL}t10k-images-idx3-ubyte.gz\"))[0x10:].reshape((-1, 28*28)).astype(np.float32)\n",
    "Y_test = parse(fetch(f\"{BASE_URL}t10k-labels-idx1-ubyte.gz\"))[8:].astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f49e3ee-7799-4719-8c70-00c19a5495ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, Y_train, optim, steps, BS=128, lossfn=lambda out, y: out.sparse_categorical_crossentropy(y),\n",
    "          transform=lambda x: x, target_transform=lambda x: x, noloss=False, allow_jit=True):\n",
    "\n",
    "  def train_step(x, y):\n",
    "    out = model.forward(x)\n",
    "    loss = lossfn(out, y)\n",
    "    optim.zero_grad() \n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    cat = out.argmax(axis=-1)\n",
    "    accuracy = (cat==y).mean()\n",
    "    return loss.realize(), accuracy.realize()\n",
    "\n",
    "  with Tensor.train():\n",
    "    losses, accuracies = [], []\n",
    "    for i in (t := trange(steps)):\n",
    "      samp = np.random.randint(0, X_train.shape[0], size=(BS))\n",
    "      x = Tensor(X_train[samp], requires_grad=False)\n",
    "      y = Tensor(Y_train[samp])\n",
    "\n",
    "      loss, accuracy = train_step(x, y)\n",
    "      loss, accuracy = loss.numpy(), accuracy.numpy()\n",
    "      losses.append(loss)\n",
    "      accuracies.append(accuracy)\n",
    "      t.set_description(\"loss %.2f accuracy %.2f\" % (loss, accuracy))\n",
    "  return [losses, accuracies]\n",
    "\n",
    "def evaluate(model, X_test, Y_test):\n",
    "  BS = 128\n",
    "  Tensor.training = False \n",
    "\n",
    "  def numpy_eval(Y_test, num_classes):\n",
    "    Y_test_preds_out = np.zeros(list(Y_test.shape) + [num_classes])\n",
    "    for i in trange((len(Y_test)-1)//BS+1):\n",
    "      x = Tensor(X_test[i*BS:(i+1)*BS])\n",
    "      out = model.forward(x)\n",
    "      Y_test_preds_out[i*BS:(i+1)*BS] = out.numpy()\n",
    "    Y_test_preds = np.argmax(Y_test_preds_out, axis=-1)\n",
    "    return (Y_test == Y_test_preds).mean(), Y_test_preds\n",
    "\n",
    "  num_classes = Y_test.max().astype(int)+1\n",
    "  acc, Y_test_pred = numpy_eval(Y_test, num_classes)\n",
    "  print(f\"test set accuracy is {acc}\")\n",
    "  return acc\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95a0c2ed-bc04-49e3-b51f-bcd2b6c2749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet:\n",
    "  def __init__(self):\n",
    "    self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "    self.conv3 = nn.Conv2d(32, 256, kernel_size=5)\n",
    "    self.linear = Tensor.scaled_uniform(256, 10)\n",
    "\n",
    "  def forward(self, x: Tensor) -> Tensor:\n",
    "    x = self.conv1(x).relu()\n",
    "    x = self.conv2(x).relu()\n",
    "    x = self.conv3(x).relu()\n",
    "    x = x.dot(self.linear)\n",
    "    return x\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34844d1d-2949-4e47-8110-bc8c9a1dd7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f4256f3-6ca8-48d9-a077-30999d8b7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = nn.optim.SGD(get_parameters(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fabc6c-1088-4d63-bc9a-a7e9ce4230fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98dc071f-26de-465d-bdef-a00be395c356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Input Tensor shape (256, 784) does not match the shape of the weights (32, 1, 5, 5). (1 vs. 784)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, X_train, Y_train, optim, steps, BS, lossfn, transform, target_transform, noloss, allow_jit)\u001b[0m\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m Tensor(X_train[samp], requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m Tensor(Y_train[samp])\n\u001b[0;32m---> 21\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mnumpy(), accuracy\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     23\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m, in \u001b[0;36mtrain.<locals>.train_step\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(x, y):\n\u001b[0;32m----> 5\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m   loss \u001b[38;5;241m=\u001b[39m lossfn(out, y)\n\u001b[1;32m      7\u001b[0m   optim\u001b[38;5;241m.\u001b[39mzero_grad() \n",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m----> 9\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[1;32m     10\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[1;32m     11\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\u001b[38;5;241m.\u001b[39mrelu()\n",
      "File \u001b[0;32m~/dev/ttt/tensor_2/.venv/lib/python3.12/site-packages/tinygrad/nn/__init__.py:52\u001b[0m, in \u001b[0;36mConv2d.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:Tensor):\n\u001b[0;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/ttt/tensor_2/.venv/lib/python3.12/site-packages/tinygrad/tensor.py:1031\u001b[0m, in \u001b[0;36mTensor.conv2d\u001b[0;34m(self, weight, bias, groups, stride, dilation, padding, acc_dtype)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconv2d\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight:Tensor, bias:Optional[Tensor]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dilation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, acc_dtype:Optional[DType]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m   1030\u001b[0m   (bs,cin_), (cout,cin), HW \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m], weight\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m], weight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m-> 1031\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m groups\u001b[38;5;241m*\u001b[39mcin \u001b[38;5;241m==\u001b[39m cin_ \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(weight\u001b[38;5;241m.\u001b[39mshape), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput Tensor shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match the shape of the weights \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroups\u001b[38;5;241m*\u001b[39mcin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcin_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, (\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;28mlist\u001b[39m)): \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(padding) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(HW) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(padding) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(HW), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected padding of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(HW)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(HW)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(padding)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for tensor of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m   padding_ \u001b[38;5;241m=\u001b[39m [padding]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(HW) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (padding \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(padding) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(HW) \u001b[38;5;28;01melse\u001b[39;00m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m padding \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m)][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Input Tensor shape (256, 784) does not match the shape of the weights (32, 1, 5, 5). (1 vs. 784)"
     ]
    }
   ],
   "source": [
    "train(model, X_train, Y_train, optimizer, 500, BS=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b340be3-48df-4aae-8a54-75b7d069b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, X_test, Y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinygrad",
   "language": "python",
   "name": "tinygrad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
